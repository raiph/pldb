import ../header.scroll
baseUrl https://pldb.io/concepts/
title chevrotain

title chevrotain - Library
 hidden

html
 <a class="trueBaseThemePreviousItem" href="pegjs.html">&lt;</a>
 <a class="trueBaseThemeNextItem" href="ninja.html">&gt;</a>

viewSourceUrl https://github.com/breck7/pldb/blob/main/concepts/chevrotain.pldb

startColumns 4

<div class="trueBaseThemeQuickLinks"><a href="http://sap.github.io/chevrotain/" class="material-symbols-outlined">home</a> <a href="https://github.com/SAP/chevrotain" class="material-symbols-outlined">code</a> <a href="/edit.html?id=chevrotain" class="material-symbols-outlined">edit</a></div>

* chevrotain is an open source <a href="/search.html?q=select+type%0D%0Awhere+type+%3D+library">library</a> created in 2015.
 link /search.html?q=select+type+appeared%0D%0Awhere+appeared+%3D+2015 2015

codeWithHeader Source code:
 git clone https://github.com/SAP/chevrotain

dashboard
 #372 on PLDB
 9 Years Old

* Parser Building Toolkit for JavaScript

- chevrotain website
 http://sap.github.io/chevrotain/
- chevrotain is developed on <a href="https://github.com/SAP/chevrotain">GitHub</a> and has 1,957 stars
- chevrotain first developed in <a href="../lists/originCommunities.html#sap">SAP</a>

<br>

codeWithHeader Example from the web:
 &quot;use strict&quot;
 /**
  * An Example of implementing a CSV Grammar with Chevrotain.
  *
  * Based on: https://github.com/antlr/grammars-v4/blob/master/csv/CSV.g4
  *
  * Note that this is a pure grammar without any actions (either embedded or via a CST Visitor).
  */
 const { createToken, Lexer, Parser, EMPTY_ALT } = require(&quot;chevrotain&quot;)
 
 // ----------------- lexer -----------------
 const Text = createToken({ name: &quot;Text&quot;, pattern: /[^,\n\r&quot;]+/ })
 const Comma = createToken({ name: &quot;Comma&quot;, pattern: /,/ })
 const NewLine = createToken({
     name: &quot;NewLine&quot;,
     pattern: /\r?\n/
 })
 const String = createToken({ name: &quot;String&quot;, pattern: /&quot;(?:&quot;&quot;|[^&quot;])*&quot;/ })
 
 const allTokens = [Text, String, Comma, NewLine]
 const CsvLexer = new Lexer(allTokens)
 
 // Parser
 class CsvParser extends Parser {
     constructor() {
         super(allTokens)
 
         // not mandatory, using $ (or any other sign) to reduce verbosity
         const $ = this
 
         $.RULE(&quot;csvFile&quot;, () =&gt; {
             $.SUBRULE($.hdr)
             $.AT_LEAST_ONE(() =&gt; {
                 $.SUBRULE2($.row)
             })
         })
 
         $.RULE(&quot;hdr&quot;, () =&gt; {
             $.SUBRULE($.row)
         })
 
         $.RULE(&quot;row&quot;, () =&gt; {
             $.SUBRULE($.field)
             $.MANY(() =&gt; {
                 $.CONSUME(Comma)
                 $.SUBRULE2($.field)
             })
             $.CONSUME(NewLine)
         })
 
         $.RULE(&quot;field&quot;, () =&gt; {
             $.OR([
                 { ALT: () =&gt; $.CONSUME(Text) },
                 { ALT: () =&gt; $.CONSUME(String) },
                 { ALT: EMPTY_ALT(&quot;empty field&quot;) }
             ])
         })
 
         // very important to call this after all the rules have been defined.
         // otherwise the parser may not work correctly as it will lack information
         // derived during the self analysis phase.
         this.performSelfAnalysis()
     }
 }
 
 // wrapping it all together
 // reuse the same parser instance.
 const parser = new CsvParser([])
 
 module.exports = function(text) {
     // 1. Tokenize the input.
     const lexResult = CsvLexer.tokenize(text)
 
     // 2. Set the Parser&#39;s input
     parser.input = lexResult.tokens
 
     // 3. invoke the desired parser rule
     const cst = parser.csvFile()
 
     return {
         cst: cst,
         lexResult: lexResult,
         parseErrors: parser.errors
     }
 }

endColumns

keyboardNav pegjs.html ninja.html

import ../footer.scroll
