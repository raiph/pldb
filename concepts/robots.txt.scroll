import ../measures/conceptPage.scroll
id Robots.txt
appeared 1994
type configFormat
creators Martijn Koster
conceptDescription A robots.txt file tells search engine crawlers which URLs the crawler can access on your site.
reference https://developers.google.com/search/docs/advanced/robots/intro
reference https://en.wikipedia.org/wiki/Robots_exclusion_standard
country United Kingdom
originCommunity https://web.archive.org/web/20131029200350/http://inkdroid.org/tmp/www-talk/4113.html

hasLineComments true
 # A comment
hasComments true
 # A comment

lineCommentToken #

example
 User-agent: googlebot        # all Google services
 Disallow: /private/          # disallow this directory
 
 User-agent: googlebot-news   # only the news service
 Disallow: /                  # disallow everything
 
 User-agent: *                # any robot
 Disallow: /something/        # disallow this directory
